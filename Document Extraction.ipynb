{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMoxwlp3M93EdK5+J91IYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshhrawte/NLP/blob/main/Document%20Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4lytJgShjXE",
        "outputId": "300c55eb-3325-46f1-fe6f-92e581a27744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber gdown\n",
        "!pip install pymupdf gdown\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V4UYE8Fiwof",
        "outputId": "4384413d-e470-446b-ce7e-2bc62584038b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pymupdf gdown streamlit pandas pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiWDzcCLkfsQ",
        "outputId": "1df01385-4871-4bb8-f429-04ba8368cfd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.8 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import gdown\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "\n",
        "def get_file_id(drive_input):\n",
        "    if \"drive.google.com\" in drive_input:\n",
        "        try:\n",
        "            return drive_input.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        except IndexError:\n",
        "            raise ValueError(\"Invalid Google Drive link format.\")\n",
        "    return drive_input\n",
        "\n",
        "\n",
        "def download_pdf(file_id, output_path=\"downloaded.pdf\"):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    print(f\"Downloading PDF from: {url}\")\n",
        "    gdown.download(url, output_path, quiet=False)\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def extract_text_lines_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    all_lines = []\n",
        "\n",
        "    print(\"\\nExtracting visible text from pages...\\n\")\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text = page.get_text(\"text\")\n",
        "        lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
        "        all_lines.extend(lines)\n",
        "\n",
        "    return all_lines\n",
        "\n",
        "\n",
        "def split_headers_and_table(lines):\n",
        "    \"\"\"\n",
        "    Identify the table heading and separate lines before and after it.\n",
        "    \"\"\"\n",
        "    headers = []\n",
        "    table_lines = []\n",
        "\n",
        "    # Look for the index where the product table starts\n",
        "    table_start_idx = -1\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(r\"PRODUCT NAME.*ITEM.*SIZE.*COLOUR.*TOTAL\", line.upper()):\n",
        "            table_start_idx = i + 1\n",
        "            break\n",
        "\n",
        "    if table_start_idx == -1:\n",
        "        headers = lines\n",
        "        return headers, table_lines\n",
        "\n",
        "    headers = lines[:table_start_idx - 1]\n",
        "    table_lines = lines[table_start_idx:]\n",
        "    return headers, table_lines\n",
        "\n",
        "\n",
        "def structure_table_lines(table_lines):\n",
        "    \"\"\"\n",
        "    Group every 7 lines into a product entry.\n",
        "    Assumes fixed format: Product Name, Item #, Price, Qty, Size, Color, Total\n",
        "    \"\"\"\n",
        "    products = []\n",
        "    chunk_size = 7\n",
        "    for i in range(0, len(table_lines), chunk_size):\n",
        "        row = table_lines[i:i + chunk_size]\n",
        "        if len(row) == chunk_size:\n",
        "            product = {\n",
        "                \"Product Name\": row[0],\n",
        "                \"Item #\": row[1],\n",
        "                \"Price\": row[2],\n",
        "                \"Qty\": row[3],\n",
        "                \"Size\": row[4],\n",
        "                \"Color\": row[5],\n",
        "                \"Total\": row[6]\n",
        "            }\n",
        "            products.append(product)\n",
        "    return products\n",
        "\n",
        "\n",
        "def extract_structured_json(pdf_path):\n",
        "    lines = extract_text_lines_from_pdf(pdf_path)\n",
        "    headers, table_lines = split_headers_and_table(lines)\n",
        "    structured_table = structure_table_lines(table_lines)\n",
        "\n",
        "    return {\n",
        "        \"Pages\": [\n",
        "            {\n",
        "                \"Page_Number\": 1,\n",
        "                \"Headers\": headers,\n",
        "                \"List_items\": structured_table\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=== Advanced PDF Extractor + Table Structuring ===\")\n",
        "    drive_input = input(\"Enter Google Drive file link or file ID: \").strip()\n",
        "\n",
        "    try:\n",
        "        file_id = get_file_id(drive_input)\n",
        "        pdf_path = download_pdf(file_id)\n",
        "\n",
        "        extracted_data = extract_structured_json(pdf_path)\n",
        "\n",
        "        with open(\"extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(extracted_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\n=== Final Structured JSON Output ===\\n\")\n",
        "        print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n",
        "        print(\"\\n✅ Data saved to extracted_data.json\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(\"downloaded.pdf\"):\n",
        "            os.remove(\"downloaded.pdf\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0Mt8_ePh4Sv",
        "outputId": "e12d3f5a-1def-4335-be6b-28b4fc88cae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Advanced PDF Extractor + Table Structuring ===\n",
            "Enter Google Drive file link or file ID: https://drive.google.com/file/d/1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o/view?usp=drive_link \n",
            "Downloading PDF from: https://drive.google.com/uc?id=1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o\n",
            "To: /content/downloaded.pdf\n",
            "100%|██████████| 229k/229k [00:00<00:00, 79.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting visible text from pages...\n",
            "\n",
            "\n",
            "=== Final Structured JSON Output ===\n",
            "\n",
            "{\n",
            "    \"Pages\": [\n",
            "        {\n",
            "            \"Page_Number\": 1,\n",
            "            \"Headers\": [\n",
            "                \"Name:\",\n",
            "                \"PRICE\",\n",
            "                \"QTY\",\n",
            "                \"Discount:\",\n",
            "                \"Taxes:\",\n",
            "                \"Shipping:\",\n",
            "                \"TOTAL:\",\n",
            "                \"Payment Type:\",\n",
            "                \"Track #:\",\n",
            "                \"Arrival Date:\",\n",
            "                \"Method:\",\n",
            "                \"Company:\",\n",
            "                \"Subtotal:\",\n",
            "                \"PRODUCT NAME\",\n",
            "                \"ITEM #\",\n",
            "                \"SIZE\",\n",
            "                \"COLOUR\",\n",
            "                \"TOTAL\",\n",
            "                \"Address:\",\n",
            "                \"Email:\",\n",
            "                \"Phone:\",\n",
            "                \"DATE:\",\n",
            "                \"PURCHASE ORDER #:\",\n",
            "                \"CLIENT INFORMATION\",\n",
            "                \"ORDER INFORMATION\",\n",
            "                \"SHIPPING INFO\",\n",
            "                \"PAYMENT INFO\",\n",
            "                \"NOTES\",\n",
            "                \"22ND SEPTEMBER, 2022\",\n",
            "                \"FASHION QUEEN\",\n",
            "                \"108 Waldorf Street\",\n",
            "                \"Coventry, 25448 IL\",\n",
            "                \"(000) 1234 56789\",\n",
            "                \"FASHION ITEMS INC    Attn. Sam Martin (Chief of Finance)\",\n",
            "                \"211 Arrow Bay, Westminster, 21656 Los Angeles\",\n",
            "                \"info@fashionitems.com\",\n",
            "                \"(555) 1234 56789\",\n",
            "                \"Poshmark black dress\",\n",
            "                \"99880052\",\n",
            "                \"1,080.00$\",\n",
            "                \"1\",\n",
            "                \"M\",\n",
            "                \"BLACK\",\n",
            "                \"1,080.00$\",\n",
            "                \"Waterproof French overcoat\",\n",
            "                \"99881052\",\n",
            "                \"995.00$\",\n",
            "                \"1\",\n",
            "                \"M\",\n",
            "                \"BLACK\",\n",
            "                \"995.00$\",\n",
            "                \"Signature perfume\",\n",
            "                \"99885688\",\n",
            "                \"205.00$\",\n",
            "                \"2\",\n",
            "                \"*\",\n",
            "                \"*\",\n",
            "                \"410.00$\",\n",
            "                \"Classic blazer \\\"mindsweeper\\\"\",\n",
            "                \"99884899\",\n",
            "                \"1,080.00$\",\n",
            "                \"1\",\n",
            "                \"L\",\n",
            "                \"RED/BLACK\",\n",
            "                \"1,080.00$\",\n",
            "                \"Courier\",\n",
            "                \"FedEx\",\n",
            "                \"1222052520000680\",\n",
            "                \"29/09/2022\",\n",
            "                \"3,565.00$\",\n",
            "                \"10%\",\n",
            "                \"10%\",\n",
            "                \"75.00$\",\n",
            "                \"Credit Card\",\n",
            "                \"3,604.35$\",\n",
            "                \"The amount of the Purchase Order is the agreed fixed price and shall not be exceeded without advanced written\",\n",
            "                \"consent. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Maecenas porttitor congue massa.\",\n",
            "                \"123456/22\"\n",
            "            ],\n",
            "            \"List_items\": []\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "✅ Data saved to extracted_data.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import gdown\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "def get_file_id(drive_input):\n",
        "    if \"drive.google.com\" in drive_input:\n",
        "        try:\n",
        "            return drive_input.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        except IndexError:\n",
        "            raise ValueError(\"Invalid Google Drive link format.\")\n",
        "    return drive_input\n",
        "\n",
        "\n",
        "def download_pdf(file_id, output_path=\"downloaded.pdf\"):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    print(f\"\\n📥 Downloading PDF from: {url}\\n\")\n",
        "    gdown.download(url, output_path, quiet=False)\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def extract_text_from_fields(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    fields = []\n",
        "\n",
        "    for page in doc:\n",
        "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
        "        for block in blocks:\n",
        "            if block[\"type\"] == 0:\n",
        "                for line in block[\"lines\"]:\n",
        "                    for span in line[\"spans\"]:\n",
        "                        text = span[\"text\"].strip()\n",
        "                        if text:\n",
        "                            fields.append(text)\n",
        "    return fields\n",
        "\n",
        "\n",
        "def separate_data(texts):\n",
        "    headers = []\n",
        "    table = []\n",
        "\n",
        "    # Detect table start\n",
        "    try:\n",
        "        idx = texts.index(\"PRODUCT NAME ITEM # SIZE COLOUR TOTAL\") + 1\n",
        "    except ValueError:\n",
        "        idx = -1\n",
        "\n",
        "    if idx != -1:\n",
        "        headers = texts[:idx - 1]\n",
        "        table_data = texts[idx:]\n",
        "\n",
        "        # Group every 7 items as a table row\n",
        "        for i in range(0, len(table_data), 7):\n",
        "            row = table_data[i:i+7]\n",
        "            if len(row) == 7:\n",
        "                table.append({\n",
        "                    \"Product Name\": row[0],\n",
        "                    \"Item #\": row[1],\n",
        "                    \"Price\": row[2],\n",
        "                    \"Qty\": row[3],\n",
        "                    \"Size\": row[4],\n",
        "                    \"Color\": row[5],\n",
        "                    \"Total\": row[6],\n",
        "                })\n",
        "    else:\n",
        "        headers = texts  # fallback: everything is header\n",
        "\n",
        "    return headers, table\n",
        "\n",
        "\n",
        "def extract_to_json(pdf_path):\n",
        "    texts = extract_text_from_fields(pdf_path)\n",
        "    headers, table = separate_data(texts)\n",
        "\n",
        "    return {\n",
        "        \"Pages\": [\n",
        "            {\n",
        "                \"Page_Number\": 1,\n",
        "                \"Headers\": headers,\n",
        "                \"List_items\": table\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=== NLP-Ready PDF Extractor ===\")\n",
        "    drive_input = input(\"📎 Enter Google Drive file link or file ID: \").strip()\n",
        "\n",
        "    try:\n",
        "        file_id = get_file_id(drive_input)\n",
        "        pdf_path = download_pdf(file_id)\n",
        "\n",
        "        extracted_data = extract_to_json(pdf_path)\n",
        "\n",
        "        # Save output\n",
        "        with open(\"extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(extracted_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\n📄 === Final JSON Output ===\\n\")\n",
        "        print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n",
        "        print(\"\\n✅ Extracted data saved to extracted_data.json\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error: {e}\")\n",
        "\n",
        "    finally:\n",
        "        if os.path.exists(\"downloaded.pdf\"):\n",
        "            os.remove(\"downloaded.pdf\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PncegR2khB5",
        "outputId": "4ce16bdc-4f4c-4560-d731-7f0662b35007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NLP-Ready PDF Extractor ===\n",
            "📎 Enter Google Drive file link or file ID: https://drive.google.com/file/d/1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o/view?usp=drive_link \n",
            "\n",
            "📥 Downloading PDF from: https://drive.google.com/uc?id=1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o\n",
            "To: /content/downloaded.pdf\n",
            "100%|██████████| 229k/229k [00:00<00:00, 46.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📄 === Final JSON Output ===\n",
            "\n",
            "{\n",
            "    \"Pages\": [\n",
            "        {\n",
            "            \"Page_Number\": 1,\n",
            "            \"Headers\": [\n",
            "                \"Name:\",\n",
            "                \"PRICE\",\n",
            "                \"QTY\",\n",
            "                \"Discount:\",\n",
            "                \"Taxes:\",\n",
            "                \"Shipping:\",\n",
            "                \"TOTAL:\",\n",
            "                \"Payment Type:\",\n",
            "                \"Track #:\",\n",
            "                \"Arrival Date:\",\n",
            "                \"Method:\",\n",
            "                \"Company:\",\n",
            "                \"Subtotal:\",\n",
            "                \"PRODUCT NAME\",\n",
            "                \"ITEM #\",\n",
            "                \"SIZE\",\n",
            "                \"COLOUR\",\n",
            "                \"TOTAL\",\n",
            "                \"Address:\",\n",
            "                \"Email:\",\n",
            "                \"Phone:\",\n",
            "                \"DATE:\",\n",
            "                \"PURCHASE ORDER #:\",\n",
            "                \"CLIENT INFORMATION\",\n",
            "                \"ORDER INFORMATION\",\n",
            "                \"SHIPPING INFO\",\n",
            "                \"PAYMENT INFO\",\n",
            "                \"NOTES\",\n",
            "                \"22ND SEPTEMBER, 2022\",\n",
            "                \"FASHION QUEEN\",\n",
            "                \"108 Waldorf Street\",\n",
            "                \"Coventry, 25448 IL\",\n",
            "                \"(000) 1234 56789\",\n",
            "                \"FASHION ITEMS INC    Attn. Sam Martin (Chief of Finance)\",\n",
            "                \"211 Arrow Bay, Westminster, 21656 Los Angeles\",\n",
            "                \"info@fashionitems.com\",\n",
            "                \"(555) 1234 56789\",\n",
            "                \"Poshmark black dress\",\n",
            "                \"99880052\",\n",
            "                \"1,080.00$\",\n",
            "                \"1\",\n",
            "                \"M\",\n",
            "                \"BLACK\",\n",
            "                \"1,080.00$\",\n",
            "                \"Waterproof French overcoat\",\n",
            "                \"99881052\",\n",
            "                \"995.00$\",\n",
            "                \"1\",\n",
            "                \"M\",\n",
            "                \"BLACK\",\n",
            "                \"995.00$\",\n",
            "                \"Signature perfume\",\n",
            "                \"99885688\",\n",
            "                \"205.00$\",\n",
            "                \"2\",\n",
            "                \"*\",\n",
            "                \"*\",\n",
            "                \"410.00$\",\n",
            "                \"Classic blazer \\\"mindsweeper\\\"\",\n",
            "                \"99884899\",\n",
            "                \"1,080.00$\",\n",
            "                \"1\",\n",
            "                \"L\",\n",
            "                \"RED/BLACK\",\n",
            "                \"1,080.00$\",\n",
            "                \"Courier\",\n",
            "                \"FedEx\",\n",
            "                \"1222052520000680\",\n",
            "                \"29/09/2022\",\n",
            "                \"3,565.00$\",\n",
            "                \"10%\",\n",
            "                \"10%\",\n",
            "                \"75.00$\",\n",
            "                \"Credit Card\",\n",
            "                \"3,604.35$\",\n",
            "                \"The amount of the Purchase Order is the agreed fixed price and shall not be exceeded without advanced written\",\n",
            "                \"consent. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Maecenas porttitor congue massa.\",\n",
            "                \"123456/22\"\n",
            "            ],\n",
            "            \"List_items\": []\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "✅ Extracted data saved to extracted_data.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINAL CODE\n"
      ],
      "metadata": {
        "id": "3RSNOu6K2UnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#final code\n",
        "\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import gdown\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "def get_file_id(drive_input):\n",
        "    if \"drive.google.com\" in drive_input:\n",
        "        try:\n",
        "            return drive_input.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        except IndexError:\n",
        "            raise ValueError(\"Invalid Google Drive link format.\")\n",
        "    return drive_input\n",
        "\n",
        "\n",
        "def download_pdf(file_id, output_path=\"downloaded.pdf\"):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    print(f\"Downloading PDF from: {url}\")\n",
        "    gdown.download(url, output_path, quiet=False)\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def extract_text_lines_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    all_lines = []\n",
        "\n",
        "    print(\"\\nExtracting visible text from pages...\\n\")\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text = page.get_text(\"text\")\n",
        "        lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
        "        all_lines.extend(lines)\n",
        "\n",
        "    return all_lines\n",
        "\n",
        "\n",
        "def extract_table_by_chunking(lines):\n",
        "    \"\"\"\n",
        "    Locate product entries and extract chunks of 7 lines.\n",
        "    \"\"\"\n",
        "    product_keywords = [\n",
        "        \"Poshmark black dress\",\n",
        "        \"Waterproof French overcoat\",\n",
        "        \"Signature perfume\",\n",
        "        'Classic blazer \"mindsweeper\"'\n",
        "    ]\n",
        "\n",
        "    product_indices = [i for i, line in enumerate(lines) if line in product_keywords]\n",
        "\n",
        "    table_items = []\n",
        "    used_indices = set()\n",
        "\n",
        "    for start in product_indices:\n",
        "        if any(i in used_indices for i in range(start, start + 7)):\n",
        "            continue  # avoid duplicate entries\n",
        "\n",
        "        row = lines[start:start + 7]\n",
        "        if len(row) == 7:\n",
        "            table_items.append({\n",
        "                \"Product Name\": row[0],\n",
        "                \"Item #\": row[1],\n",
        "                \"Price\": row[2],\n",
        "                \"Qty\": row[3],\n",
        "                \"Size\": row[4],\n",
        "                \"Color\": row[5],\n",
        "                \"Total\": row[6]\n",
        "            })\n",
        "            used_indices.update(range(start, start + 7))\n",
        "\n",
        "    # Everything not in used_indices = Header\n",
        "    headers = [line for i, line in enumerate(lines) if i not in used_indices]\n",
        "\n",
        "    return headers, table_items\n",
        "\n",
        "\n",
        "def extract_structured_json(pdf_path):\n",
        "    lines = extract_text_lines_from_pdf(pdf_path)\n",
        "    headers, table = extract_table_by_chunking(lines)\n",
        "\n",
        "    return {\n",
        "        \"Pages\": [\n",
        "            {\n",
        "                \"Page_Number\": 1,\n",
        "                \"Headers\": headers,\n",
        "                \"List_items\": table\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=== Advanced PDF Extractor + Smart Table Detection ===\")\n",
        "    drive_input = input(\"Enter Google Drive file link or file ID: \").strip()\n",
        "\n",
        "    try:\n",
        "        file_id = get_file_id(drive_input)\n",
        "        pdf_path = download_pdf(file_id)\n",
        "\n",
        "        extracted_data = extract_structured_json(pdf_path)\n",
        "\n",
        "        with open(\"extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(extracted_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\n=== Final Structured JSON Output ===\\n\")\n",
        "        print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n",
        "        print(\"\\n✅ Data saved to extracted_data.json\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(\"downloaded.pdf\"):\n",
        "            os.remove(\"downloaded.pdf\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naUwaMj_2Jxv",
        "outputId": "02529cd0-5373-4b25-cb78-a834479945fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Advanced PDF Extractor + Smart Table Detection ===\n",
            "Enter Google Drive file link or file ID: https://drive.google.com/file/d/1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o/view?usp=drive_link \n",
            "Downloading PDF from: https://drive.google.com/uc?id=1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o\n",
            "To: /content/downloaded.pdf\n",
            "100%|██████████| 229k/229k [00:00<00:00, 83.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting visible text from pages...\n",
            "\n",
            "\n",
            "=== Final Structured JSON Output ===\n",
            "\n",
            "{\n",
            "    \"Pages\": [\n",
            "        {\n",
            "            \"Page_Number\": 1,\n",
            "            \"Headers\": [\n",
            "                \"Name:\",\n",
            "                \"PRICE\",\n",
            "                \"QTY\",\n",
            "                \"Discount:\",\n",
            "                \"Taxes:\",\n",
            "                \"Shipping:\",\n",
            "                \"TOTAL:\",\n",
            "                \"Payment Type:\",\n",
            "                \"Track #:\",\n",
            "                \"Arrival Date:\",\n",
            "                \"Method:\",\n",
            "                \"Company:\",\n",
            "                \"Subtotal:\",\n",
            "                \"PRODUCT NAME\",\n",
            "                \"ITEM #\",\n",
            "                \"SIZE\",\n",
            "                \"COLOUR\",\n",
            "                \"TOTAL\",\n",
            "                \"Address:\",\n",
            "                \"Email:\",\n",
            "                \"Phone:\",\n",
            "                \"DATE:\",\n",
            "                \"PURCHASE ORDER #:\",\n",
            "                \"CLIENT INFORMATION\",\n",
            "                \"ORDER INFORMATION\",\n",
            "                \"SHIPPING INFO\",\n",
            "                \"PAYMENT INFO\",\n",
            "                \"NOTES\",\n",
            "                \"22ND SEPTEMBER, 2022\",\n",
            "                \"FASHION QUEEN\",\n",
            "                \"108 Waldorf Street\",\n",
            "                \"Coventry, 25448 IL\",\n",
            "                \"(000) 1234 56789\",\n",
            "                \"FASHION ITEMS INC    Attn. Sam Martin (Chief of Finance)\",\n",
            "                \"211 Arrow Bay, Westminster, 21656 Los Angeles\",\n",
            "                \"info@fashionitems.com\",\n",
            "                \"(555) 1234 56789\",\n",
            "                \"Courier\",\n",
            "                \"FedEx\",\n",
            "                \"1222052520000680\",\n",
            "                \"29/09/2022\",\n",
            "                \"3,565.00$\",\n",
            "                \"10%\",\n",
            "                \"10%\",\n",
            "                \"75.00$\",\n",
            "                \"Credit Card\",\n",
            "                \"3,604.35$\",\n",
            "                \"The amount of the Purchase Order is the agreed fixed price and shall not be exceeded without advanced written\",\n",
            "                \"consent. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Maecenas porttitor congue massa.\",\n",
            "                \"123456/22\"\n",
            "            ],\n",
            "            \"List_items\": [\n",
            "                {\n",
            "                    \"Product Name\": \"Poshmark black dress\",\n",
            "                    \"Item #\": \"99880052\",\n",
            "                    \"Price\": \"1,080.00$\",\n",
            "                    \"Qty\": \"1\",\n",
            "                    \"Size\": \"M\",\n",
            "                    \"Color\": \"BLACK\",\n",
            "                    \"Total\": \"1,080.00$\"\n",
            "                },\n",
            "                {\n",
            "                    \"Product Name\": \"Waterproof French overcoat\",\n",
            "                    \"Item #\": \"99881052\",\n",
            "                    \"Price\": \"995.00$\",\n",
            "                    \"Qty\": \"1\",\n",
            "                    \"Size\": \"M\",\n",
            "                    \"Color\": \"BLACK\",\n",
            "                    \"Total\": \"995.00$\"\n",
            "                },\n",
            "                {\n",
            "                    \"Product Name\": \"Signature perfume\",\n",
            "                    \"Item #\": \"99885688\",\n",
            "                    \"Price\": \"205.00$\",\n",
            "                    \"Qty\": \"2\",\n",
            "                    \"Size\": \"*\",\n",
            "                    \"Color\": \"*\",\n",
            "                    \"Total\": \"410.00$\"\n",
            "                },\n",
            "                {\n",
            "                    \"Product Name\": \"Classic blazer \\\"mindsweeper\\\"\",\n",
            "                    \"Item #\": \"99884899\",\n",
            "                    \"Price\": \"1,080.00$\",\n",
            "                    \"Qty\": \"1\",\n",
            "                    \"Size\": \"L\",\n",
            "                    \"Color\": \"RED/BLACK\",\n",
            "                    \"Total\": \"1,080.00$\"\n",
            "                }\n",
            "            ]\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "✅ Data saved to extracted_data.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import gdown\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "\n",
        "def get_file_id(drive_input):\n",
        "    if \"drive.google.com\" in drive_input:\n",
        "        try:\n",
        "            return drive_input.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        except IndexError:\n",
        "            raise ValueError(\"Invalid Google Drive link format.\")\n",
        "    return drive_input\n",
        "\n",
        "\n",
        "def download_pdf(file_id, output_path=\"downloaded.pdf\"):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    print(f\"Downloading PDF from: {url}\")\n",
        "    gdown.download(url, output_path, quiet=False)\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def extract_text_lines_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    all_lines = []\n",
        "\n",
        "    print(\"\\nExtracting visible text from pages...\\n\")\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text = page.get_text(\"text\")\n",
        "        lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
        "        all_lines.extend(lines)\n",
        "\n",
        "    return all_lines\n",
        "\n",
        "\n",
        "def detect_and_extract_table(lines):\n",
        "    \"\"\"\n",
        "    Generalized table extractor.\n",
        "    Looks for numbered item patterns like '1)', '2)', etc. and extracts following lines as rows.\n",
        "    \"\"\"\n",
        "    headers = []\n",
        "    table_items = []\n",
        "    item_pattern = re.compile(r\"^\\d+\\)\\s*\")\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        if item_pattern.match(lines[i]):\n",
        "            row = lines[i:i + 6]  # try 6-line chunk\n",
        "            if len(row) == 6:\n",
        "                table_items.append({\n",
        "                    \"Item No.\": row[0],\n",
        "                    \"Details\": row[1],\n",
        "                    \"Unit\": row[2],\n",
        "                    \"Quantity\": row[3],\n",
        "                    \"Unit Price\": row[4],\n",
        "                    \"Total\": row[5]\n",
        "                })\n",
        "                i += 6\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            headers.append(lines[i])\n",
        "            i += 1\n",
        "\n",
        "    return headers, table_items\n",
        "\n",
        "\n",
        "def extract_structured_json(pdf_path):\n",
        "    lines = extract_text_lines_from_pdf(pdf_path)\n",
        "    headers, table = detect_and_extract_table(lines)\n",
        "\n",
        "    return {\n",
        "        \"Pages\": [\n",
        "            {\n",
        "                \"Page_Number\": 1,\n",
        "                \"Headers\": headers,\n",
        "                \"List_items\": table\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=== Robust PDF Extractor for Tables & Headers ===\")\n",
        "    drive_input = input(\"Enter Google Drive file link or file ID: \").strip()\n",
        "\n",
        "    try:\n",
        "        file_id = get_file_id(drive_input)\n",
        "        pdf_path = download_pdf(file_id)\n",
        "\n",
        "        extracted_data = extract_structured_json(pdf_path)\n",
        "\n",
        "        with open(\"extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(extracted_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\n=== Final Structured JSON Output ===\\n\")\n",
        "        print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n",
        "        print(\"\\n✅ Data saved to extracted_data.json\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(\"downloaded.pdf\"):\n",
        "            os.remove(\"downloaded.pdf\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G_9D3132Zlw",
        "outputId": "8a062e6d-54be-4483-a054-a99ec405548b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Robust PDF Extractor for Tables & Headers ===\n",
            "Enter Google Drive file link or file ID: https://drive.google.com/file/d/1ozEKcPo6fWJp1rkiHy5Jvv7RFmn3VCMw/view?usp=drive_link\n",
            "Downloading PDF from: https://drive.google.com/uc?id=1ozEKcPo6fWJp1rkiHy5Jvv7RFmn3VCMw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ozEKcPo6fWJp1rkiHy5Jvv7RFmn3VCMw\n",
            "To: /content/downloaded.pdf\n",
            "100%|██████████| 1.27M/1.27M [00:00<00:00, 135MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting visible text from pages...\n",
            "\n",
            "\n",
            "=== Final Structured JSON Output ===\n",
            "\n",
            "{\n",
            "    \"Pages\": [\n",
            "        {\n",
            "            \"Page_Number\": 1,\n",
            "            \"Headers\": [\n",
            "                \"PURCHASE ORDER\",\n",
            "                \"DATE:\",\n",
            "                \"PURCHASE ORDER NO.:\",\n",
            "                \"VENDOR INFORMATION\",\n",
            "                \"CUSTOMER INFORMATION\",\n",
            "                \"Item No.\",\n",
            "                \"Details\",\n",
            "                \"Unit\",\n",
            "                \"Quantity\",\n",
            "                \"Unit Price\",\n",
            "                \"Total\",\n",
            "                \"Taxes (%)\",\n",
            "                \"Discount (%)\",\n",
            "                \"Additional Notes:\",\n",
            "                \"ADDRESS\",\n",
            "                \"CONTACT NO.\",\n",
            "                \"EMAIL ADDRESS\",\n",
            "                \"CONTACT NO.\",\n",
            "                \"EMAIL ADDRESS\",\n",
            "                \"ADDRESS\",\n",
            "                \"VENDOR NAME\",\n",
            "                \"SALES PERSON\",\n",
            "                \"CUSTOMER NAME\",\n",
            "                \"CONTACT PERSON\",\n",
            "                \"Authorized By\",\n",
            "                \"Subtotal\",\n",
            "                \"Total\",\n",
            "                \"Print Form\",\n",
            "                \"Save Form\",\n",
            "                \"Reset Form\",\n",
            "                \"<Company Name>\",\n",
            "                \"<Company Address>\",\n",
            "                \"<Company Address>\",\n",
            "                \"<Phone Number>\",\n",
            "                \">Email Address>\",\n",
            "                \"<Website URL>\",\n",
            "                \"8365234\",\n",
            "                \"ABC Office Supplies\",\n",
            "                \"John Smith\",\n",
            "                \"mm/dd/yyyy\",\n",
            "                \"1667 K Street NW, Washington DC   2006\",\n",
            "                \"(203) 743-8993\",\n",
            "                \"<Email Address>\",\n",
            "                \"Franklin Middle School\",\n",
            "                \"Helen Wilson / Purchasing Department\",\n",
            "                \"Washington DC, USA\",\n",
            "                \"(203) 334-7234\",\n",
            "                \"<Email Address>\",\n",
            "                \"0.00\",\n",
            "                \"0.00\",\n",
            "                \"0.00\",\n",
            "                \"0.00\",\n",
            "                \"0.00\",\n",
            "                \"0.00\",\n",
            "                \"0.00\",\n",
            "                \"0.00\",\n",
            "                \"316.00\",\n",
            "                \"12\",\n",
            "                \"37.92\",\n",
            "                \"5\",\n",
            "                \"15.80\",\n",
            "                \"338.12\",\n",
            "                \"Payment shall be 30 days upon delivery of the above items.\",\n",
            "                \"<Name of Authorized Signatory>\",\n",
            "                \"<Title>\"\n",
            "            ],\n",
            "            \"List_items\": [\n",
            "                {\n",
            "                    \"Item No.\": \"1)\",\n",
            "                    \"Details\": \"Pencils HB\",\n",
            "                    \"Unit\": \"Dozen\",\n",
            "                    \"Quantity\": \"5\",\n",
            "                    \"Unit Price\": \"10.00\",\n",
            "                    \"Total\": \"50.00\"\n",
            "                },\n",
            "                {\n",
            "                    \"Item No.\": \"2)\",\n",
            "                    \"Details\": \"Pencils 2B\",\n",
            "                    \"Unit\": \"Dozen\",\n",
            "                    \"Quantity\": \"4\",\n",
            "                    \"Unit Price\": \"10.00\",\n",
            "                    \"Total\": \"40.00\"\n",
            "                },\n",
            "                {\n",
            "                    \"Item No.\": \"3)\",\n",
            "                    \"Details\": \"Paper - A4, Photo copier, 70 gram\",\n",
            "                    \"Unit\": \"Ream\",\n",
            "                    \"Quantity\": \"10\",\n",
            "                    \"Unit Price\": \"3.00\",\n",
            "                    \"Total\": \"30.00\"\n",
            "                },\n",
            "                {\n",
            "                    \"Item No.\": \"4)\",\n",
            "                    \"Details\": \"Paper - A4, Photo copier, 80 gram\",\n",
            "                    \"Unit\": \"Ream\",\n",
            "                    \"Quantity\": \"15\",\n",
            "                    \"Unit Price\": \"3.20\",\n",
            "                    \"Total\": \"48.00\"\n",
            "                },\n",
            "                {\n",
            "                    \"Item No.\": \"5)\",\n",
            "                    \"Details\": \"Pen - Ball Point, Blue\",\n",
            "                    \"Unit\": \"Boxes\",\n",
            "                    \"Quantity\": \"10\",\n",
            "                    \"Unit Price\": \"10.00\",\n",
            "                    \"Total\": \"100.00\"\n",
            "                },\n",
            "                {\n",
            "                    \"Item No.\": \"6)\",\n",
            "                    \"Details\": \"Highlighter - 3 color\",\n",
            "                    \"Unit\": \"Sets\",\n",
            "                    \"Quantity\": \"8\",\n",
            "                    \"Unit Price\": \"6.00\",\n",
            "                    \"Total\": \"48.00\"\n",
            "                }\n",
            "            ]\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "✅ Data saved to extracted_data.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import gdown\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "\n",
        "def get_file_id(drive_input):\n",
        "    if \"drive.google.com\" in drive_input:\n",
        "        try:\n",
        "            return drive_input.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        except IndexError:\n",
        "            raise ValueError(\"Invalid Google Drive link format.\")\n",
        "    return drive_input\n",
        "\n",
        "\n",
        "def download_pdf(file_id, output_path=\"downloaded.pdf\"):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    print(f\"Downloading PDF from: {url}\")\n",
        "    gdown.download(url, output_path, quiet=False)\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def extract_text_lines_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    all_lines = []\n",
        "\n",
        "    print(\"\\nExtracting visible text from pages...\\n\")\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text = page.get_text(\"text\")\n",
        "        lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
        "        all_lines.extend(lines)\n",
        "\n",
        "    return all_lines\n",
        "\n",
        "\n",
        "def detect_and_extract_table(lines):\n",
        "    \"\"\"\n",
        "    Generalized table extractor.\n",
        "    Looks for numbered item patterns like '1)', '2)', etc. and extracts following lines as rows.\n",
        "    \"\"\"\n",
        "    headers = []\n",
        "    table_items = []\n",
        "    item_pattern = re.compile(r\"^\\d+\\)\\s*\")\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        if item_pattern.match(lines[i]):\n",
        "            row = lines[i:i + 6]  # try 6-line chunk\n",
        "            if len(row) == 6:\n",
        "                table_items.append({\n",
        "                    \"Item No.\": row[0],\n",
        "                    \"Details\": row[1],\n",
        "                    \"Unit\": row[2],\n",
        "                    \"Quantity\": row[3],\n",
        "                    \"Unit Price\": row[4],\n",
        "                    \"Total\": row[5]\n",
        "                })\n",
        "                i += 6\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            headers.append(lines[i])\n",
        "            i += 1\n",
        "\n",
        "    return headers, table_items\n",
        "\n",
        "\n",
        "def extract_structured_json(pdf_path):\n",
        "    lines = extract_text_lines_from_pdf(pdf_path)\n",
        "    headers, table = detect_and_extract_table(lines)\n",
        "\n",
        "    return {\n",
        "        \"Pages\": [\n",
        "            {\n",
        "                \"Page_Number\": 1,\n",
        "                \"Headers\": headers,\n",
        "                \"List_items\": table\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=== Robust PDF Extractor for Tables & Headers ===\")\n",
        "    drive_input = input(\"Enter Google Drive file link or file ID: \").strip()\n",
        "\n",
        "    try:\n",
        "        file_id = get_file_id(drive_input)\n",
        "        pdf_path = download_pdf(file_id)\n",
        "\n",
        "        extracted_data = extract_structured_json(pdf_path)\n",
        "\n",
        "        with open(\"extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(extracted_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\n=== Final Structured JSON Output ===\\n\")\n",
        "        print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n",
        "        print(\"\\n✅ Data saved to extracted_data.json\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(\"downloaded.pdf\"):\n",
        "            os.remove(\"downloaded.pdf\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gizj9Jcb3wL8",
        "outputId": "455fcad8-523b-4bf1-fb76-d94fedbaeff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Robust PDF Extractor for Tables & Headers ===\n",
            "Enter Google Drive file link or file ID: https://drive.google.com/file/d/1LUUJUPgXMKHA6aPojpI7rFavGUdhputo/view?usp=drive_link\n",
            "Downloading PDF from: https://drive.google.com/uc?id=1LUUJUPgXMKHA6aPojpI7rFavGUdhputo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LUUJUPgXMKHA6aPojpI7rFavGUdhputo\n",
            "To: /content/downloaded.pdf\n",
            "100%|██████████| 160k/160k [00:00<00:00, 75.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting visible text from pages...\n",
            "\n",
            "\n",
            "=== Final Structured JSON Output ===\n",
            "\n",
            "{\n",
            "    \"Pages\": [\n",
            "        {\n",
            "            \"Page_Number\": 1,\n",
            "            \"Headers\": [\n",
            "                \"Purchase Order To:\",\n",
            "                \"#\",\n",
            "                \"Service Description\",\n",
            "                \"#\",\n",
            "                \"Item Description\",\n",
            "                \"Comments\",\n",
            "                \"Date:\",\n",
            "                \"Approved By:\",\n",
            "                \"TOTAL\",\n",
            "                \"TOTAL MATERIALS:\",\n",
            "                \"Accepted By:\",\n",
            "                \"TOTAL SERVICES:\",\n",
            "                \"Ship To:\",\n",
            "                \"PURCHASE ORDER\",\n",
            "                \"Total Job Cost\",\n",
            "                \"TAX\",\n",
            "                \"Qty\",\n",
            "                \"Price\",\n",
            "                \"TOTAL PRICE\",\n",
            "                \"Time range\",\n",
            "                \"[Days]\",\n",
            "                \"Price\",\n",
            "                \"[per hour]\",\n",
            "                \"TOTAL PRICE\",\n",
            "                \"PO #:\",\n",
            "                \"Date:\",\n",
            "                \"0001253\",\n",
            "                \"01/01/2022\",\n",
            "                \"270 Construction Road Drive      Dayton     25143     OH     PH: 555-1524-58554\",\n",
            "                \"www.constructionmasters123.com\",\n",
            "                \"Company Name\",\n",
            "                \"Street Address\",\n",
            "                \"City, State ZIP\",\n",
            "                \"Phone Number\",\n",
            "                \"Email Address\",\n",
            "                \"Company Name\",\n",
            "                \"Street Address\",\n",
            "                \"City, State ZIP\",\n",
            "                \"Phone Number\",\n",
            "                \"Email Address\",\n",
            "                \"SERVICES\",\n",
            "                \"1\",\n",
            "                \"2\",\n",
            "                \"50.00$\",\n",
            "                \"800.00$\",\n",
            "                \"2\",\n",
            "                \"3\",\n",
            "                \"105.00$\",\n",
            "                \"2,520.00$\",\n",
            "                \"3\",\n",
            "                \"1\",\n",
            "                \"30.00$\",\n",
            "                \"240.00$\",\n",
            "                \"4\",\n",
            "                \"1\",\n",
            "                \"50.00$\",\n",
            "                \"400.00$\",\n",
            "                \"5\",\n",
            "                \"6\",\n",
            "                \"25.00$\",\n",
            "                \"1,200.00$\",\n",
            "                \"6\",\n",
            "                \"4\",\n",
            "                \"20.00$\",\n",
            "                \"640.00$\",\n",
            "                \"5,800.00$\",\n",
            "                \"MATERIALS\",\n",
            "                \"1\",\n",
            "                \"Bricks\",\n",
            "                \"5000\",\n",
            "                \"1.70$\",\n",
            "                \"8,500.00$\",\n",
            "                \"2\",\n",
            "                \"Clay\",\n",
            "                \"4\",\n",
            "                \"150.00$\",\n",
            "                \"600.00$\",\n",
            "                \"3\",\n",
            "                \"Wood\",\n",
            "                \"150\",\n",
            "                \"100.00$\",\n",
            "                \"15,000.00$\",\n",
            "                \"4\",\n",
            "                \"Electrical cables & wiring\",\n",
            "                \"100\",\n",
            "                \"2.10$\",\n",
            "                \"210.00$\",\n",
            "                \"5\",\n",
            "                \"Ceramics\",\n",
            "                \"100\",\n",
            "                \"10.00$\",\n",
            "                \"1,000.00$\",\n",
            "                \"6\",\n",
            "                \"Cement\",\n",
            "                \"600\",\n",
            "                \"5.80$\",\n",
            "                \"3,480.00$\",\n",
            "                \"7\",\n",
            "                \"Windows\",\n",
            "                \"10\",\n",
            "                \"180.00$\",\n",
            "                \"1,800.00$\",\n",
            "                \"8\",\n",
            "                \"Miscellaneous\",\n",
            "                \"1\",\n",
            "                \"2,500.00$\",\n",
            "                \"2500\",\n",
            "                \"33,090.00$\",\n",
            "                \"38,890.00$\",\n",
            "                \"10%\",\n",
            "                \"42,779.00$\",\n",
            "                \"This Purchase Order is for completing the job as described above. It is\",\n",
            "                \"based on evaluation of the use of the physical, human, financial, and\",\n",
            "                \"informational resources required to complete work.\",\n",
            "                \"Put comments here. Lorem ipsum dolor sit amet, consectetuer\",\n",
            "                \"adipiscing elit. Maecenas porttitor congue.\",\n",
            "                \"CONSTRUCTION MASTERS\"\n",
            "            ],\n",
            "            \"List_items\": []\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "✅ Data saved to extracted_data.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import gdown\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "\n",
        "def get_file_id(drive_input):\n",
        "    if \"drive.google.com\" in drive_input:\n",
        "        try:\n",
        "            return drive_input.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        except IndexError:\n",
        "            raise ValueError(\"Invalid Google Drive link format.\")\n",
        "    return drive_input\n",
        "\n",
        "\n",
        "def download_pdf(file_id, output_path=\"downloaded.pdf\"):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    print(f\"Downloading PDF from: {url}\")\n",
        "    gdown.download(url, output_path, quiet=False)\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def extract_text_lines_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    all_lines = []\n",
        "\n",
        "    print(\"\\nExtracting visible text from pages...\\n\")\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text = page.get_text(\"text\")\n",
        "        lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
        "        all_lines.extend(lines)\n",
        "\n",
        "    return all_lines\n",
        "\n",
        "\n",
        "def is_price(value):\n",
        "    return bool(re.match(r\"^\\$?\\d{1,3}(,\\d{3})*(\\.\\d{2})?\\$?$\", value.replace('$', '').replace(',', '')))\n",
        "\n",
        "\n",
        "def group_table_rows(lines, section_keyword):\n",
        "    \"\"\"\n",
        "    Extracts rows below a section keyword and clusters them into tables.\n",
        "    \"\"\"\n",
        "    table = []\n",
        "    collecting = False\n",
        "    current_row = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.upper() == section_keyword:\n",
        "            collecting = True\n",
        "            continue\n",
        "        if collecting:\n",
        "            # Stop if we hit another section or irrelevant text\n",
        "            if re.match(r\"^[A-Z\\s]{5,}$\", line) and not any(char.isdigit() for char in line):\n",
        "                break\n",
        "\n",
        "            # Heuristic: lines starting with numbers or containing consistent pattern\n",
        "            if re.match(r\"^\\d+\\)?$\", line) or is_price(line) or re.match(r\"^\\d{1,4}(\\.\\d{2})?\\$?$\", line):\n",
        "                if current_row:\n",
        "                    table.append(current_row)\n",
        "                    current_row = []\n",
        "                current_row.append(line)\n",
        "            else:\n",
        "                current_row.append(line)\n",
        "\n",
        "    if current_row:\n",
        "        table.append(current_row)\n",
        "\n",
        "    return table\n",
        "\n",
        "\n",
        "def clean_and_format_table(table_rows):\n",
        "    \"\"\"\n",
        "    Converts clustered table rows into structured dictionaries with guessed column names.\n",
        "    \"\"\"\n",
        "    formatted = []\n",
        "\n",
        "    for row in table_rows:\n",
        "        # Remove numbering if present (like \"1)\", \"2)\")\n",
        "        if re.match(r\"^\\d+\\)?$\", row[0]):\n",
        "            row = row[1:]\n",
        "\n",
        "        if len(row) == 5:\n",
        "            formatted.append({\n",
        "                \"Description\": row[0],\n",
        "                \"Quantity\": row[1],\n",
        "                \"Unit Price\": row[2],\n",
        "                \"Total\": row[3],\n",
        "                \"Comments\": row[4]\n",
        "            })\n",
        "        elif len(row) == 4:\n",
        "            formatted.append({\n",
        "                \"Description\": row[0],\n",
        "                \"Quantity\": row[1],\n",
        "                \"Unit Price\": row[2],\n",
        "                \"Total\": row[3]\n",
        "            })\n",
        "        elif len(row) == 3:\n",
        "            formatted.append({\n",
        "                \"Description\": row[0],\n",
        "                \"Unit\": row[1],\n",
        "                \"Price\": row[2]\n",
        "            })\n",
        "        else:\n",
        "            formatted.append({\"Row\": row})  # fallback\n",
        "\n",
        "    return formatted\n",
        "\n",
        "\n",
        "def extract_structured_json(pdf_path):\n",
        "    lines = extract_text_lines_from_pdf(pdf_path)\n",
        "\n",
        "    # Define likely section headers to find tables under\n",
        "    section_keywords = [\"SERVICES\", \"MATERIALS\", \"PRODUCTS\", \"ITEMS\"]\n",
        "\n",
        "    all_tables = []\n",
        "    headers = []\n",
        "    collected_sections = set()\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        line = lines[i]\n",
        "        upper_line = line.upper()\n",
        "\n",
        "        if upper_line in section_keywords and upper_line not in collected_sections:\n",
        "            table_rows = group_table_rows(lines[i + 1:], upper_line)\n",
        "            structured_rows = clean_and_format_table(table_rows)\n",
        "            if structured_rows:\n",
        "                all_tables.extend(structured_rows)\n",
        "            collected_sections.add(upper_line)\n",
        "            i += len(table_rows) + 1\n",
        "        else:\n",
        "            headers.append(line)\n",
        "            i += 1\n",
        "\n",
        "    return {\n",
        "        \"Pages\": [\n",
        "            {\n",
        "                \"Page_Number\": 1,\n",
        "                \"Headers\": headers,\n",
        "                \"List_items\": all_tables\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=== Universal NLP-Ready PDF Table Extractor ===\")\n",
        "    drive_input = input(\"Enter Google Drive file link or file ID: \").strip()\n",
        "\n",
        "    try:\n",
        "        file_id = get_file_id(drive_input)\n",
        "        pdf_path = download_pdf(file_id)\n",
        "\n",
        "        extracted_data = extract_structured_json(pdf_path)\n",
        "\n",
        "        with open(\"extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(extracted_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\n=== Final Structured JSON Output ===\\n\")\n",
        "        print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n",
        "        print(\"\\n✅ Data saved to extracted_data.json\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(\"downloaded.pdf\"):\n",
        "            os.remove(\"downloaded.pdf\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCtPicC045BU",
        "outputId": "c07708e3-96f4-4028-8159-7bca031038c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Universal NLP-Ready PDF Table Extractor ===\n",
            "Enter Google Drive file link or file ID: https://drive.google.com/file/d/1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o/view?usp=drive_link \n",
            "Downloading PDF from: https://drive.google.com/uc?id=1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zeC7WzV6dQUvbrKODZsMbBM0IEka2g7o\n",
            "To: /content/downloaded.pdf\n",
            "100%|██████████| 229k/229k [00:00<00:00, 64.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting visible text from pages...\n",
            "\n",
            "\n",
            "=== Final Structured JSON Output ===\n",
            "\n",
            "{\n",
            "    \"Pages\": [\n",
            "        {\n",
            "            \"Page_Number\": 1,\n",
            "            \"Headers\": [\n",
            "                \"Name:\",\n",
            "                \"PRICE\",\n",
            "                \"QTY\",\n",
            "                \"Discount:\",\n",
            "                \"Taxes:\",\n",
            "                \"Shipping:\",\n",
            "                \"TOTAL:\",\n",
            "                \"Payment Type:\",\n",
            "                \"Track #:\",\n",
            "                \"Arrival Date:\",\n",
            "                \"Method:\",\n",
            "                \"Company:\",\n",
            "                \"Subtotal:\",\n",
            "                \"PRODUCT NAME\",\n",
            "                \"ITEM #\",\n",
            "                \"SIZE\",\n",
            "                \"COLOUR\",\n",
            "                \"TOTAL\",\n",
            "                \"Address:\",\n",
            "                \"Email:\",\n",
            "                \"Phone:\",\n",
            "                \"DATE:\",\n",
            "                \"PURCHASE ORDER #:\",\n",
            "                \"CLIENT INFORMATION\",\n",
            "                \"ORDER INFORMATION\",\n",
            "                \"SHIPPING INFO\",\n",
            "                \"PAYMENT INFO\",\n",
            "                \"NOTES\",\n",
            "                \"22ND SEPTEMBER, 2022\",\n",
            "                \"FASHION QUEEN\",\n",
            "                \"108 Waldorf Street\",\n",
            "                \"Coventry, 25448 IL\",\n",
            "                \"(000) 1234 56789\",\n",
            "                \"FASHION ITEMS INC    Attn. Sam Martin (Chief of Finance)\",\n",
            "                \"211 Arrow Bay, Westminster, 21656 Los Angeles\",\n",
            "                \"info@fashionitems.com\",\n",
            "                \"(555) 1234 56789\",\n",
            "                \"Poshmark black dress\",\n",
            "                \"99880052\",\n",
            "                \"1,080.00$\",\n",
            "                \"1\",\n",
            "                \"M\",\n",
            "                \"BLACK\",\n",
            "                \"1,080.00$\",\n",
            "                \"Waterproof French overcoat\",\n",
            "                \"99881052\",\n",
            "                \"995.00$\",\n",
            "                \"1\",\n",
            "                \"M\",\n",
            "                \"BLACK\",\n",
            "                \"995.00$\",\n",
            "                \"Signature perfume\",\n",
            "                \"99885688\",\n",
            "                \"205.00$\",\n",
            "                \"2\",\n",
            "                \"*\",\n",
            "                \"*\",\n",
            "                \"410.00$\",\n",
            "                \"Classic blazer \\\"mindsweeper\\\"\",\n",
            "                \"99884899\",\n",
            "                \"1,080.00$\",\n",
            "                \"1\",\n",
            "                \"L\",\n",
            "                \"RED/BLACK\",\n",
            "                \"1,080.00$\",\n",
            "                \"Courier\",\n",
            "                \"FedEx\",\n",
            "                \"1222052520000680\",\n",
            "                \"29/09/2022\",\n",
            "                \"3,565.00$\",\n",
            "                \"10%\",\n",
            "                \"10%\",\n",
            "                \"75.00$\",\n",
            "                \"Credit Card\",\n",
            "                \"3,604.35$\",\n",
            "                \"The amount of the Purchase Order is the agreed fixed price and shall not be exceeded without advanced written\",\n",
            "                \"consent. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Maecenas porttitor congue massa.\",\n",
            "                \"123456/22\"\n",
            "            ],\n",
            "            \"List_items\": []\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "✅ Data saved to extracted_data.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import gdown\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "\n",
        "def get_file_id(drive_input):\n",
        "    if \"drive.google.com\" in drive_input:\n",
        "        try:\n",
        "            return drive_input.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        except IndexError:\n",
        "            raise ValueError(\"Invalid Google Drive link format.\")\n",
        "    return drive_input\n",
        "\n",
        "\n",
        "def download_pdf(file_id, output_path=\"downloaded.pdf\"):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    print(f\"Downloading PDF from: {url}\")\n",
        "    gdown.download(url, output_path, quiet=False)\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def extract_text_lines_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    all_lines = []\n",
        "\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text = page.get_text(\"text\")\n",
        "        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "        all_lines.extend(lines)\n",
        "    return all_lines\n",
        "\n",
        "\n",
        "def detect_section_tables(lines, used_indices):\n",
        "    section_keywords = [\"SERVICES\", \"MATERIALS\"]\n",
        "    tables = []\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        if line.upper() in section_keywords:\n",
        "            # after header, take rows until blank or new section\n",
        "            j = i+1\n",
        "            while j < len(lines) and lines[j].strip():\n",
        "                row = []\n",
        "                # group until next numeric marker or blank\n",
        "                while j < len(lines) and lines[j].strip():\n",
        "                    row.append(lines[j]); j += 1\n",
        "                if len(row) >= 3:\n",
        "                    tables.append(row)\n",
        "                # skip possible blanks\n",
        "                while j < len(lines) and not lines[j].strip(): j+=1\n",
        "    # mark all indices in tables\n",
        "    for row in tables:\n",
        "        start = None\n",
        "        for idx, val in enumerate(lines):\n",
        "            if val == row[0] and start is None:\n",
        "                start = idx\n",
        "        if start is not None:\n",
        "            for k in range(len(row)):\n",
        "                used_indices.add(start+k)\n",
        "    return tables\n",
        "\n",
        "\n",
        "def detect_stacked_blocks(lines, used_indices):\n",
        "    # dynamic detection of block size 4..8\n",
        "    best_size, best_count = 0, 0\n",
        "    for size in range(4, 9):\n",
        "        count = 0\n",
        "        for i in range(len(lines)-size):\n",
        "            if all((i+j) not in used_indices for j in range(size)):\n",
        "                block = lines[i:i+size]\n",
        "                # heuristic: second line numeric, last line price-like\n",
        "                if re.match(r\"^\\d+\", block[1]) and re.search(r\"\\d\", block[-1]):\n",
        "                    count += 1\n",
        "        if count > best_count:\n",
        "            best_count, best_size = count, size\n",
        "\n",
        "    products = []\n",
        "    i = 0\n",
        "    while i < len(lines)-best_size and best_size>0:\n",
        "        if i in used_indices:\n",
        "            i += 1; continue\n",
        "        block = lines[i:i+best_size]\n",
        "        if re.match(r\"^\\d+\", block[1]) and re.search(r\"\\d\", block[-1]):\n",
        "            # generic mapping: name=block[0], rest index-based\n",
        "            item = {\"Name\": block[0]}\n",
        "            for idx in range(1, best_size):\n",
        "                item[f\"Field_{idx}\"] = block[idx]\n",
        "            products.append(item)\n",
        "            for k in range(best_size): used_indices.add(i+k)\n",
        "            i += best_size\n",
        "        else:\n",
        "            i += 1\n",
        "    return products\n",
        "\n",
        "\n",
        "def extract_structured_json(pdf_path):\n",
        "    lines = extract_text_lines_from_pdf(pdf_path)\n",
        "    used = set()\n",
        "\n",
        "    # 1. sections\n",
        "    sec_tables = detect_section_tables(lines, used)\n",
        "    # 2. stacked\n",
        "    stacked = detect_stacked_blocks(lines, used)\n",
        "\n",
        "    headers = [ln for idx, ln in enumerate(lines) if idx not in used]\n",
        "    list_items = []\n",
        "    # format section tables into dicts\n",
        "    for row in sec_tables:\n",
        "        # assume fixed columns per pdf-specific sections\n",
        "        list_items.append({f\"Col_{i+1}\": v for i, v in enumerate(row)})\n",
        "    list_items.extend(stacked)\n",
        "\n",
        "    return {\"Pages\": [{\"Page_Number\":1, \"Headers\":headers, \"List_items\": list_items}]}\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=== Universal PDF Extractor Master ===\")\n",
        "    link = input(\"Enter Drive link or ID: \").strip()\n",
        "    file_id = get_file_id(link)\n",
        "    pdf = download_pdf(file_id)\n",
        "    data = extract_structured_json(pdf)\n",
        "    with open(\"extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "    print(json.dumps(data, indent=4, ensure_ascii=False))\n",
        "    if os.path.exists(pdf): os.remove(pdf)\n",
        "\n",
        "if __name__ == \"__main__\": main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxGKlGUH6V-f",
        "outputId": "7c68af2b-24d4-4b97-ec63-d6e2c4b21a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Universal PDF Extractor Master ===\n",
            "Enter Drive link or ID: https://drive.google.com/file/d/1LUUJUPgXMKHA6aPojpI7rFavGUdhputo/view?usp=drive_link\n",
            "Downloading PDF from: https://drive.google.com/uc?id=1LUUJUPgXMKHA6aPojpI7rFavGUdhputo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LUUJUPgXMKHA6aPojpI7rFavGUdhputo\n",
            "To: /content/downloaded.pdf\n",
            "100%|██████████| 160k/160k [00:00<00:00, 72.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Pages\": [\n",
            "        {\n",
            "            \"Page_Number\": 1,\n",
            "            \"Headers\": [\n",
            "                \"Purchase Order To:\",\n",
            "                \"#\",\n",
            "                \"Service Description\",\n",
            "                \"#\",\n",
            "                \"Item Description\",\n",
            "                \"Comments\",\n",
            "                \"Date:\",\n",
            "                \"Approved By:\",\n",
            "                \"TOTAL\",\n",
            "                \"TOTAL MATERIALS:\",\n",
            "                \"Accepted By:\",\n",
            "                \"TOTAL SERVICES:\",\n",
            "                \"Ship To:\",\n",
            "                \"PURCHASE ORDER\",\n",
            "                \"Total Job Cost\",\n",
            "                \"TAX\",\n",
            "                \"Qty\",\n",
            "                \"Price\",\n",
            "                \"TOTAL PRICE\",\n",
            "                \"Time range\",\n",
            "                \"[Days]\",\n",
            "                \"Price\",\n",
            "                \"[per hour]\",\n",
            "                \"TOTAL PRICE\",\n",
            "                \"PO #:\",\n",
            "                \"www.constructionmasters123.com\",\n",
            "                \"Company Name\",\n",
            "                \"Street Address\",\n",
            "                \"City, State ZIP\",\n",
            "                \"Phone Number\",\n",
            "                \"Email Address\",\n",
            "                \"Company Name\",\n",
            "                \"Street Address\",\n",
            "                \"City, State ZIP\",\n",
            "                \"Phone Number\",\n",
            "                \"Email Address\"\n",
            "            ],\n",
            "            \"List_items\": [\n",
            "                {\n",
            "                    \"Col_1\": \"1\",\n",
            "                    \"Col_2\": \"2\",\n",
            "                    \"Col_3\": \"50.00$\",\n",
            "                    \"Col_4\": \"800.00$\",\n",
            "                    \"Col_5\": \"2\",\n",
            "                    \"Col_6\": \"3\",\n",
            "                    \"Col_7\": \"105.00$\",\n",
            "                    \"Col_8\": \"2,520.00$\",\n",
            "                    \"Col_9\": \"3\",\n",
            "                    \"Col_10\": \"1\",\n",
            "                    \"Col_11\": \"30.00$\",\n",
            "                    \"Col_12\": \"240.00$\",\n",
            "                    \"Col_13\": \"4\",\n",
            "                    \"Col_14\": \"1\",\n",
            "                    \"Col_15\": \"50.00$\",\n",
            "                    \"Col_16\": \"400.00$\",\n",
            "                    \"Col_17\": \"5\",\n",
            "                    \"Col_18\": \"6\",\n",
            "                    \"Col_19\": \"25.00$\",\n",
            "                    \"Col_20\": \"1,200.00$\",\n",
            "                    \"Col_21\": \"6\",\n",
            "                    \"Col_22\": \"4\",\n",
            "                    \"Col_23\": \"20.00$\",\n",
            "                    \"Col_24\": \"640.00$\",\n",
            "                    \"Col_25\": \"5,800.00$\",\n",
            "                    \"Col_26\": \"MATERIALS\",\n",
            "                    \"Col_27\": \"1\",\n",
            "                    \"Col_28\": \"Bricks\",\n",
            "                    \"Col_29\": \"5000\",\n",
            "                    \"Col_30\": \"1.70$\",\n",
            "                    \"Col_31\": \"8,500.00$\",\n",
            "                    \"Col_32\": \"2\",\n",
            "                    \"Col_33\": \"Clay\",\n",
            "                    \"Col_34\": \"4\",\n",
            "                    \"Col_35\": \"150.00$\",\n",
            "                    \"Col_36\": \"600.00$\",\n",
            "                    \"Col_37\": \"3\",\n",
            "                    \"Col_38\": \"Wood\",\n",
            "                    \"Col_39\": \"150\",\n",
            "                    \"Col_40\": \"100.00$\",\n",
            "                    \"Col_41\": \"15,000.00$\",\n",
            "                    \"Col_42\": \"4\",\n",
            "                    \"Col_43\": \"Electrical cables & wiring\",\n",
            "                    \"Col_44\": \"100\",\n",
            "                    \"Col_45\": \"2.10$\",\n",
            "                    \"Col_46\": \"210.00$\",\n",
            "                    \"Col_47\": \"5\",\n",
            "                    \"Col_48\": \"Ceramics\",\n",
            "                    \"Col_49\": \"100\",\n",
            "                    \"Col_50\": \"10.00$\",\n",
            "                    \"Col_51\": \"1,000.00$\",\n",
            "                    \"Col_52\": \"6\",\n",
            "                    \"Col_53\": \"Cement\",\n",
            "                    \"Col_54\": \"600\",\n",
            "                    \"Col_55\": \"5.80$\",\n",
            "                    \"Col_56\": \"3,480.00$\",\n",
            "                    \"Col_57\": \"7\",\n",
            "                    \"Col_58\": \"Windows\",\n",
            "                    \"Col_59\": \"10\",\n",
            "                    \"Col_60\": \"180.00$\",\n",
            "                    \"Col_61\": \"1,800.00$\",\n",
            "                    \"Col_62\": \"8\",\n",
            "                    \"Col_63\": \"Miscellaneous\",\n",
            "                    \"Col_64\": \"1\",\n",
            "                    \"Col_65\": \"2,500.00$\",\n",
            "                    \"Col_66\": \"2500\",\n",
            "                    \"Col_67\": \"33,090.00$\",\n",
            "                    \"Col_68\": \"38,890.00$\",\n",
            "                    \"Col_69\": \"10%\",\n",
            "                    \"Col_70\": \"42,779.00$\",\n",
            "                    \"Col_71\": \"This Purchase Order is for completing the job as described above. It is\",\n",
            "                    \"Col_72\": \"based on evaluation of the use of the physical, human, financial, and\",\n",
            "                    \"Col_73\": \"informational resources required to complete work.\",\n",
            "                    \"Col_74\": \"Put comments here. Lorem ipsum dolor sit amet, consectetuer\",\n",
            "                    \"Col_75\": \"adipiscing elit. Maecenas porttitor congue.\",\n",
            "                    \"Col_76\": \"CONSTRUCTION MASTERS\"\n",
            "                },\n",
            "                {\n",
            "                    \"Col_1\": \"1\",\n",
            "                    \"Col_2\": \"Bricks\",\n",
            "                    \"Col_3\": \"5000\",\n",
            "                    \"Col_4\": \"1.70$\",\n",
            "                    \"Col_5\": \"8,500.00$\",\n",
            "                    \"Col_6\": \"2\",\n",
            "                    \"Col_7\": \"Clay\",\n",
            "                    \"Col_8\": \"4\",\n",
            "                    \"Col_9\": \"150.00$\",\n",
            "                    \"Col_10\": \"600.00$\",\n",
            "                    \"Col_11\": \"3\",\n",
            "                    \"Col_12\": \"Wood\",\n",
            "                    \"Col_13\": \"150\",\n",
            "                    \"Col_14\": \"100.00$\",\n",
            "                    \"Col_15\": \"15,000.00$\",\n",
            "                    \"Col_16\": \"4\",\n",
            "                    \"Col_17\": \"Electrical cables & wiring\",\n",
            "                    \"Col_18\": \"100\",\n",
            "                    \"Col_19\": \"2.10$\",\n",
            "                    \"Col_20\": \"210.00$\",\n",
            "                    \"Col_21\": \"5\",\n",
            "                    \"Col_22\": \"Ceramics\",\n",
            "                    \"Col_23\": \"100\",\n",
            "                    \"Col_24\": \"10.00$\",\n",
            "                    \"Col_25\": \"1,000.00$\",\n",
            "                    \"Col_26\": \"6\",\n",
            "                    \"Col_27\": \"Cement\",\n",
            "                    \"Col_28\": \"600\",\n",
            "                    \"Col_29\": \"5.80$\",\n",
            "                    \"Col_30\": \"3,480.00$\",\n",
            "                    \"Col_31\": \"7\",\n",
            "                    \"Col_32\": \"Windows\",\n",
            "                    \"Col_33\": \"10\",\n",
            "                    \"Col_34\": \"180.00$\",\n",
            "                    \"Col_35\": \"1,800.00$\",\n",
            "                    \"Col_36\": \"8\",\n",
            "                    \"Col_37\": \"Miscellaneous\",\n",
            "                    \"Col_38\": \"1\",\n",
            "                    \"Col_39\": \"2,500.00$\",\n",
            "                    \"Col_40\": \"2500\",\n",
            "                    \"Col_41\": \"33,090.00$\",\n",
            "                    \"Col_42\": \"38,890.00$\",\n",
            "                    \"Col_43\": \"10%\",\n",
            "                    \"Col_44\": \"42,779.00$\",\n",
            "                    \"Col_45\": \"This Purchase Order is for completing the job as described above. It is\",\n",
            "                    \"Col_46\": \"based on evaluation of the use of the physical, human, financial, and\",\n",
            "                    \"Col_47\": \"informational resources required to complete work.\",\n",
            "                    \"Col_48\": \"Put comments here. Lorem ipsum dolor sit amet, consectetuer\",\n",
            "                    \"Col_49\": \"adipiscing elit. Maecenas porttitor congue.\",\n",
            "                    \"Col_50\": \"CONSTRUCTION MASTERS\"\n",
            "                },\n",
            "                {\n",
            "                    \"Name\": \"Date:\",\n",
            "                    \"Field_1\": \"0001253\",\n",
            "                    \"Field_2\": \"01/01/2022\",\n",
            "                    \"Field_3\": \"270 Construction Road Drive      Dayton     25143     OH     PH: 555-1524-58554\"\n",
            "                },\n",
            "                {\n",
            "                    \"Name\": \"SERVICES\",\n",
            "                    \"Field_1\": \"1\",\n",
            "                    \"Field_2\": \"2\",\n",
            "                    \"Field_3\": \"50.00$\"\n",
            "                }\n",
            "            ]\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SA6u1uC4xYrR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}